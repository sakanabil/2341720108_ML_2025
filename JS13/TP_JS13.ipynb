{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPA1+GcOgL/MDfttnLuGxNs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Tugas"],"metadata":{"id":"NvhIFBzaoz4L"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qsZld_-vn7Qr","executionInfo":{"status":"ok","timestamp":1764168669119,"user_tz":-420,"elapsed":88516,"user":{"displayName":"Saka Nabil","userId":"07598593331632767827"}},"outputId":"cc9c7b92-81fb-4677-95d3-496fdb2efd64"},"outputs":[{"output_type":"stream","name":"stdout","text":["Memuat dan memproses data MNIST...\n","Data siap.\n","Kompilasi model...\n","Melatih model (10 epochs)...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Pelatihan selesai.\n","\n","=============================================\n","Akurasi pada data uji: 0.9789\n","Loss pada data uji: 0.1050\n","=============================================\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Flatten\n","from tensorflow.keras.utils import to_categorical\n","import numpy as np\n","\n","# 1. Load dataset MNIST\n","print(\"Memuat dan memproses data MNIST...\")\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","# Normalisasi data (0-255 → 0-1)\n","X_train = X_train / 255.0\n","X_test = X_test / 255.0\n","\n","# One-hot encoding label\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","print(\"Data siap.\")\n","\n","# 2. Bangun model JST\n","# Menggunakan konfigurasi 2 hidden layer (256 dan 128) dari eksperimen sebelumnya\n","model = Sequential([\n","    # Ubah gambar 28x28 menjadi vektor (28 * 28 = 784 fitur)\n","    tf.keras.layers.Flatten(input_shape=(28, 28)),\n","\n","    # Hidden layer 1: 256 neuron, aktivasi ReLU\n","    tf.keras.layers.Dense(256, activation='relu'),\n","\n","    # Hidden layer 2: 128 neuron, aktivasi ReLU\n","    tf.keras.layers.Dense(128, activation='relu'),\n","\n","    # Output layer (10 kelas), aktivasi Softmax\n","    tf.keras.layers.Dense(10, activation='softmax')\n","])\n","\n","# 3. Kompilasi model (MANDATORY)\n","print(\"Kompilasi model...\")\n","model.compile(optimizer='adam',\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","# 4. Latih model (MANDATORY)\n","print(\"Melatih model (10 epochs)...\")\n","model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=0)\n","print(\"Pelatihan selesai.\")\n","\n","# 5. Evaluasi model\n","loss, acc = model.evaluate(X_test, y_test, verbose=0)\n","print(f\"\\n=============================================\")\n","print(f\"Akurasi pada data uji: {acc:.4f}\")\n","print(f\"Loss pada data uji: {loss:.4f}\")\n","print(\"=============================================\")"]},{"cell_type":"markdown","source":["Coba dengan beberapa parameter lain"],"metadata":{"id":"zWkl5dwdoCj5"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Flatten\n","from tensorflow.keras.utils import to_categorical\n","from time import time\n","import numpy as np\n","\n","# Pengaturan Global\n","EPOCHS = 10\n","BATCH_SIZE = 32\n","tf.random.set_seed(42) # Agar inisialisasi bobot konsisten\n","\n","# 1. Load dataset MNIST\n","print(\"Memuat dan memproses data MNIST...\")\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","# Normalisasi data (0-255 → 0-1)\n","X_train = X_train / 255.0\n","X_test = X_test / 255.0\n","\n","# One-hot encoding label\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","print(\"Data siap.\\n\")\n","\n","# --- Fungsi Eksperimen ---\n","def run_experiment(hidden_layers, activation_func, model_name):\n","    print(f\"=============================================================\")\n","    print(f\"EKSPERIMEN: {model_name}\")\n","    print(f\"Layer: {len(hidden_layers)} Hidden Layers ({hidden_layers}) | Aktivasi: {activation_func}\")\n","\n","    # 2. Bangun model JST\n","    model = Sequential([\n","        # Ubah gambar 28x28 menjadi vektor\n","        Flatten(input_shape=(28, 28))\n","    ])\n","\n","    # Tambahkan Hidden Layer sesuai konfigurasi\n","    for neurons in hidden_layers:\n","        model.add(Dense(neurons, activation=activation_func))\n","\n","    # Output layer (10 kelas)\n","    model.add(Dense(10, activation='softmax'))\n","\n","    # 3. Kompilasi model\n","    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","    # 4. Latih model\n","    start_time = time()\n","    history = model.fit(\n","        X_train, y_train,\n","        epochs=EPOCHS,\n","        batch_size=BATCH_SIZE,\n","        verbose=0 # Atur ke 0 agar output lebih rapi\n","    )\n","    end_time = time()\n","\n","    training_time = end_time - start_time\n","\n","    # 5. Evaluasi model\n","    loss, acc = model.evaluate(X_test, y_test, verbose=0)\n","\n","    print(f\"Waktu Pelatihan: {training_time:.2f} detik\")\n","    print(f\"Loss pada data uji: {loss:.4f}\")\n","    print(f\"Akurasi pada data uji: {acc:.4f}\")\n","\n","    return acc, training_time, loss\n","\n","# --- Menjalankan Eksperimen ---\n","\n","results = {}\n","\n","# 1. Baseline (Konfigurasi 2 Hidden Layer - ReLU)\n","results['Baseline (256, 128, ReLU)'] = run_experiment(\n","    hidden_layers=[256, 128],\n","    activation_func='relu',\n","    model_name=\"1. BASELINE (2 Layers, ReLU)\"\n",")\n","\n","# 2. Model Lebih Dalam (3 Hidden Layer - ReLU)\n","results['Deeper (256, 128, 64, ReLU)'] = run_experiment(\n","    hidden_layers=[256, 128, 64],\n","    activation_func='relu',\n","    model_name=\"2. MODEL LEBIH DALAM (3 Layers, ReLU)\"\n",")\n","\n","# 3. Model Lebih Dalam (3 Hidden Layer - Sigmoid)\n","results['Deeper (256, 128, 64, Sigmoid)'] = run_experiment(\n","    hidden_layers=[256, 128, 64],\n","    activation_func='sigmoid',\n","    model_name=\"3. PERBANDINGAN AKTIVASI (3 Layers, Sigmoid)\"\n",")\n","\n","print(f\"\\n=============================================================\")\n","print(\"REKAPITULASI HASIL EKSPERIMEN MNIST\")\n","print(\"=============================================================\")\n","print(\"Model | Akurasi | Waktu Pelatihan (s) | Loss\")\n","print(\"-\" * 50)\n","for name, res in results.items():\n","    print(f\"{name:30} | {res[0]:.4f} | {res[1]:^19.2f} | {res[2]:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LGLl5M_noFKZ","executionInfo":{"status":"ok","timestamp":1764168945352,"user_tz":-420,"elapsed":266289,"user":{"displayName":"Saka Nabil","userId":"07598593331632767827"}},"outputId":"4eb074ee-1484-4ef3-e0e4-e75a9b141e1d"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Memuat dan memproses data MNIST...\n","Data siap.\n","\n","=============================================================\n","EKSPERIMEN: 1. BASELINE (2 Layers, ReLU)\n","Layer: 2 Hidden Layers ([256, 128]) | Aktivasi: relu\n","Waktu Pelatihan: 86.46 detik\n","Loss pada data uji: 0.1063\n","Akurasi pada data uji: 0.9788\n","=============================================================\n","EKSPERIMEN: 2. MODEL LEBIH DALAM (3 Layers, ReLU)\n","Layer: 3 Hidden Layers ([256, 128, 64]) | Aktivasi: relu\n","Waktu Pelatihan: 89.06 detik\n","Loss pada data uji: 0.1104\n","Akurasi pada data uji: 0.9772\n","=============================================================\n","EKSPERIMEN: 3. PERBANDINGAN AKTIVASI (3 Layers, Sigmoid)\n","Layer: 3 Hidden Layers ([256, 128, 64]) | Aktivasi: sigmoid\n","Waktu Pelatihan: 87.15 detik\n","Loss pada data uji: 0.0876\n","Akurasi pada data uji: 0.9775\n","\n","=============================================================\n","REKAPITULASI HASIL EKSPERIMEN MNIST\n","=============================================================\n","Model | Akurasi | Waktu Pelatihan (s) | Loss\n","--------------------------------------------------\n","Baseline (256, 128, ReLU)      | 0.9788 |        86.46        | 0.1063\n","Deeper (256, 128, 64, ReLU)    | 0.9772 |        89.06        | 0.1104\n","Deeper (256, 128, 64, Sigmoid) | 0.9775 |        87.15        | 0.0876\n"]}]}]}